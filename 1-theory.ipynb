{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbcb8046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Problem definition - What problem are we trying to solve?\n",
    "# - Supervised\n",
    "# - Unsupervised\n",
    "# - Classification\n",
    "# - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a37ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data - We need this to find the pattern in problem\n",
    "# - Structures - Rows, Columns, Excel Spredsheet\n",
    "# - Unstractured - Image, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d7f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Evaluation - We define what success for us?\n",
    "# We know the perfect model doesn't exists!\n",
    "# We need atleast 95% accurate model are predecting the cost of houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32538757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Features - What do we already know about the data?\n",
    "# Heart disease ? - we need to know body weight of the patient (body weight is a number, it's called numeric feature)\n",
    "# our goal is to turn these features into patterns to know if the user has heart deases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2da84cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Modelling - Based on our problem and data, what model should we use?\n",
    "# We already have bunch of model created by experts, we just need to use those\n",
    "# but choosing the correct model depends on the solvers, who decides which type of problem required which type of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5397e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Experimentation - How could we improve/what can we try next?\n",
    "# You make multiple attemps to experiment with our data set to find out which model works the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a505395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These all the steps are iterative in nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f054f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Problem definition\n",
    "# What problem are we trying to solve?\n",
    "\n",
    "# Machine learning is not a solution for every problem, so when should'nt you use machine learning?\n",
    "# - will a sample hand-coded instruction based system work?\n",
    "# - if you know the solution already and it doesn't required too much rational thinking, please don't use ML\n",
    "\n",
    "# Main types of machine learning\n",
    "# - Supervised Learning (Most common onces)\n",
    "#   Here you have data and labels, A ML algo tries to use the data to predict a label, if it guess the label wrong the algo corrects itself and trys again, this active correction is why it calles supervised\n",
    "#   Classification\n",
    "#     - Is this example one thing or another?\n",
    "#     - Binary classification = two options\n",
    "#     - Multi-class classification = more than two options\n",
    "#   Regression\n",
    "#     - How much will this house sell for?\n",
    "#     - How many people will buy this app?\n",
    "#   I Know my input and outputs. Like finding if a patient has Heart Disease or What should be the house cost?\n",
    "\n",
    "# - Unsupervised Learning (Most common onces)\n",
    "#   It has data but not label, you might have a purchsing history of all customer at your store, and the marketing team wants a send a promotion message to all those customer for next summer, but they know that \n",
    "#   not everybody is interested, they need to figure our who is interest into summer sale, based on the purchasing history pattern of the customer data\n",
    "#   You decide to run an algo to group the customer data into two different category, Summer and Winter\n",
    "#   One group purchase on summer\n",
    "#   Another group purchase on winter\n",
    "#   You then send these data to marketing team so the can prevent sending unnessosry data to those who are least interested\n",
    "#   NOTE: Your provided the label by grouping them, such as summer and winter, (this is also called clustering)\n",
    "#   I'm not sure of the outputs but i have inputs.\n",
    "\n",
    "# - Transfer Learning (Most common onces)\n",
    "#   here the models leavrage the learning of another models, you can use already trained model in your project to save time and uses other model learning\n",
    "#   You can even use the foundation steps of other model which are similar to what you are going to do\n",
    "#   I think my problem may be similar to something else.\n",
    "\n",
    "# - Reinforcement Learning\n",
    "#   It is where reward and punishment plays the import role, machine decides on it's own my maximizing the points internally to find what is good/bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a14565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data\n",
    "# What kind of data do we have?\n",
    "\n",
    "# Different types of data\n",
    "\n",
    "# Structured - Rows, Column, it means one column contains same types of data, like age column has numeric data\n",
    "# Unstractured - Image, Audio, it means we can turn this into number so each image has also can be turned into array of numbers\n",
    "\n",
    "# Static Data - Which doesn't change over time, CSV\n",
    "# Streaming Data - Which changes because on realtime changes, like stock prices based on news headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ac1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Evalution\n",
    "# What defines success for us?\n",
    "\n",
    "# Example: \"For this project to be worth pursuing further, we need a machine learning model with over 99% accuracy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00997e42",
   "metadata": {},
   "source": [
    "Different types of metrics\n",
    "\n",
    "| Classfication | Regression | Recommendation |\n",
    "|---------------|------------|----------------|\n",
    "| Accuracy | Mean absolute error (MAE) | Precision at K |\n",
    "| Precision | Mean squared error (MSE) | - |\n",
    "| Recall | Root mean squared error (RMSE) | - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae7a6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Features\n",
    "# What do we already know about the data?\n",
    "\n",
    "# Feature is another word for different kind of data! it can be structured or unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e757ade",
   "metadata": {},
   "source": [
    "Different features of data\n",
    "\n",
    "| ID | Weight | Sex | Heart Rate | Chest Pain | Heart Disease ? |\n",
    "| -----| --------| --- | --- | --- |---|\n",
    "| 4326 | 110 Kg | M | 81 | 4 | Yes |\n",
    "| 5681 | 64 Kg | F | 61 | 1 | No |\n",
    "| 7911 | 81 Kg | M | 57 | 0 | No |\n",
    "\n",
    "Table 1.0: Patient Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c588d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex, Weight, Heart Rate can be used to predict if they have heart disease of not\n",
    "# these are what we called features\n",
    "\n",
    "# We can also call this Feature Variables\n",
    "\n",
    "# While we also have what we called Target Variable? ex: Heart Disease?\n",
    "\n",
    "# So we use Feature Variables to Predict The target variables\n",
    "\n",
    "# We have different types of features\n",
    "# - Numerical Features = heart rate, chest pain, weight\n",
    "# - Categorical Features = sex, heart disease\n",
    "\n",
    "# You can create new features from the existing once, called \"Derived Features\"\n",
    "# The process of creating these derived features like these out of data are called \"Feature Engineering\"\n",
    "\n",
    "# Feature Engineering: Looking at different features of data and creating new ones/altering exisiting ones.\n",
    "\n",
    "# Unstructured Data also can have \"Derived Features\"\n",
    "\n",
    "# Feature coverage: How many samples have different features? Ideally, every sample has the same features.\n",
    "\n",
    "# What are features of your problems? numerical or categorical or you derived from the data and created derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0633dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Modelling Part 1 - 3 Sets\n",
    "# Based on our problem and data, what model should we use?\n",
    "\n",
    "# 3 Parts to modelling\n",
    "# - Choosing and training a model\n",
    "# - Tuning a model\n",
    "# - Model comparison\n",
    "\n",
    "# The most important concept in machine learning\n",
    "# - The training, validation and test sets or also knowns as 3 Sets\n",
    "\n",
    "# Your Data > Split (3 Set) [Training Set - Train your model on this, Validation Set - Tune your model on this, Test Set - Test and compare on this]\n",
    "\n",
    "# The 3 Sets Modelling Example:\n",
    "# 1. Course Materials (Training Set)\n",
    "# 2. Practice Exam (Validation Set)\n",
    "# 3. Final Exam (Test Set) - also provide unseen data, else the student will always pass\n",
    "\n",
    "# Generalization: The ability for a machine learning model to perform well on data it hasn't seen before\n",
    "\n",
    "# The 3 Sets Data Split: (Suppose you have 100 patients, shuffle the patients data, then do the following)\n",
    "# 1. 70-80% Training Split\n",
    "# 2. 10-15% Validation Split\n",
    "# 3. 10-15% Test Split\n",
    "\n",
    "# Usally 70-80% on training and 30-20% on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af5bd012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Modelling Part 2 - Choosing\n",
    "# Based on our problem and data, what model should we use?\n",
    "\n",
    "# 3 Parts to modelling\n",
    "# - Choosing and training a model\n",
    "#   - Training Data\n",
    "# - Tuning a model\n",
    "#   - Validation Data\n",
    "# - Model comparison\n",
    "#   - Test Data\n",
    "\n",
    "# Choosing a model - unlike creating your own machine learning model, there are plantly out there already ready for you to use.\n",
    "\n",
    "# Example:\n",
    "# Problem 1 - Model 1\n",
    "# Peoblem 2 - Model 2\n",
    "\n",
    "# If working with:\n",
    "# - Structured Data = CatBoost, dmlc XGBoost, Random Forest\n",
    "# - Unstructured Data = Deep Learning, Transfer Learning\n",
    "\n",
    "# Training a model\n",
    "\n",
    "# Example:\n",
    "# Input -> ML Model -> Output [X]\n",
    "# Input -> ML Model -> Output [✅] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382c29bb",
   "metadata": {},
   "source": [
    "x (data) to predict y (label)\n",
    "\n",
    "| ID | Weight | Sex | Heart Rate | Chest Pain | Heart Disease ? |\n",
    "| -----| --------| --- | --- | --- |---|\n",
    "| 4326 | 110 Kg | M | 81 | 4 | Yes |\n",
    "| 5681 | 64 Kg | F | 61 | 1 | No |\n",
    "| 7911 | 81 Kg | M | 57 | 0 | No |\n",
    "\n",
    "Table 1.0: Patient Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e47e4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Minimise time between experiments\n",
    "\n",
    "# Always try to train model with least amount of data first to test it's perfrom and reduce time between experiments\n",
    "\n",
    "# Experiment:\n",
    "# 1. Input -> Model 1 -> Outputs -> Accurecy(87.5%) -> Traning Time(3 min)\n",
    "# 2. Input -> Model 2 -> Outputs -> Accurecy(91.3%) -> Traning Time(92 min)\n",
    "# 3. Input -> Model 3 -> Outputs -> Accurecy(94.7%) -> Traning Time(176 min)\n",
    "\n",
    "# Things to remember\n",
    "# - Some models work better than others on different problems\n",
    "# - Don't be afraid to try things (this is very iterative process, don't fear)\n",
    "# - Start small and build up (add complexity) as you need - start with simple model and go up to latest and greatest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd7c4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Modelling Part 3 - Tuning\n",
    "# Based on our problem and data, what model should we use?\n",
    "\n",
    "# Tuning a model\n",
    "#  - Validation Data (this happens on validation data set split, based on how you done your training data set)\n",
    "\n",
    "# You tweek the params on the model to see different output as you change these values\n",
    "\n",
    "# Things to remember\n",
    "# - Machine learning models have hyperparameters you can adjust\n",
    "# - A models first results aren't its last\n",
    "# - Tuning can take place on training or validation data sets\n",
    "\n",
    "# You should always do model tuning at the time of traning and testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19b1c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Modelling Part 4 - Comparison\n",
    "# How will our model perform in the real world?\n",
    "\n",
    "# Model comparison\n",
    "#  - Test Data (This is where if your train your model correctly, then we can see how better your models are perfroming against the unkown data set)\n",
    "\n",
    "# A good trained model will always yield the similar result on Training, Validation and Test Data Set\n",
    "# And it's not uncommon to see a slight decline in perfromance from the model on the traning and validation set to the test set\n",
    "# For example your model on training data set might achieve 98% accurecy result while 96% accurecy on the test set\n",
    "\n",
    "# Underfitting (potential): Training(64%), Test(47%) - when training set perfromance is higer then test set.\n",
    "# Overfitting (potential) : Training(93%), Test(99%) - when test set performance is higher then training set.\n",
    "\n",
    "# Overfitting/Underfitting are the examples where models are unable to generalize well which is what we DONT WANT.\n",
    "\n",
    "# We want balanced zone - it's a iterative process to achive this\n",
    "\n",
    "# Overfitting/Underfitting - caused by data leak from training data to test data.\n",
    "\n",
    "# Data mismatch - happens when training data set is different from test data set. feature mismatched, can lead to model perfroming poorly.\n",
    "# Training data should be as same as what you are going to test on\n",
    "\n",
    "# Fixes for overfitting and underfitting\n",
    "# Underfitting\n",
    "# - Try a more adavance model\n",
    "# - Increase model hyperparamerters\n",
    "# - Reduce amount of features\n",
    "# - Train longer\n",
    "\n",
    "# Overfitting - it means either the model is too good, or you shaped your training data set too perfect, but either ways, remember no model is perfect\n",
    "# - Collect more data\n",
    "# - Try a less advanced model\n",
    "\n",
    "# Things to remember: \n",
    "# - Want to avoid overfitting and underfitting (head towards generality)\n",
    "# - Keep the test set separete at all costs\n",
    "# - compare apples to apples and oranges to oranges, keep the features same\n",
    "# - One best perfromace matric does not equal best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29544e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Experimentation\n",
    "# How could we improve / what can we try new?\n",
    "\n",
    "# - Step 1: Problem Defination (Someone might come to you with data set and ask you to find insight on it)\n",
    "# - Step 2, 3, 4: Data Analysis (Iterative process to refine data and know about the data)\n",
    "# - Step 5: Build ML Model (Once you know little bit more about the data)\n",
    "# - Step 6: Try different Model (see if this perfrom better model or new model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d8d7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create A Framework ✅ (Problem definition, Data, Evaluation, Features, Modelling, Experiments) - iterative process\n",
    "# 2. Match to data science and machine learning tools\n",
    "# 3. Learn by doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea9cb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools we nee\n",
    "#     [Data Science]\n",
    "#      - - Install Anaconda\n",
    "#      - - Jupyter Notebook\n",
    "#     [Data Analysis]\n",
    "#      - - Matplotlib\n",
    "#      - - NumPy\n",
    "#      - - Panda\n",
    "#     [Modelling]\n",
    "#      - - Scikit Learn\n",
    "#      - - XGBoost\n",
    "#      - - Pytorch\n",
    "#      - - Tensorflow\n",
    "#      - - CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932718ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
